{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请完成本文件内所有的TODO部分\n",
    "# 参考multihead attention相关源代码\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "def count_corpus(tokens):\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "\n",
    "def tokenize(lines): # char level\n",
    "    return [list(line) for line in lines]\n",
    "\n",
    "def read_time_machine():\n",
    "    \n",
    "    with open('./data/timemachine.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1): \n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines)\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = load_corpus_time_machine()\n",
    "import torch, random\n",
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y\n",
    "        \n",
    "class SeqDataLoader:  \n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        self.data_iter_fn = seq_data_iter_sequential\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n",
    "\n",
    "def load_data_time_machine(batch_size, num_steps,  \n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"返回时光机器数据集的迭代器和词表\"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    return data_iter, data_iter.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "\n",
    "        # 计算注意力分数，将结果除以 sqrt(d) 来标准化\n",
    "        # hint: 使用 torch.bmm 或者 @运算 来进行批量矩阵乘法\n",
    "        # TODO\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        \n",
    "        # 掩蔽无效位置，对剩下位置计算softmax归一化后的注意力分数\n",
    "        # TODO   \n",
    "        attention_weights = masked_softmax(scores, valid_lens)\n",
    "        \n",
    "        # 把注意力分数和对应的values相乘\n",
    "        # TODO\n",
    "        result = torch.bmm(self.dropout(attention_weights), values)\n",
    "\n",
    "        return result\n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "\n",
    "    #@save\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values一开始的形状: (batch_size，L，num_hiddens)\n",
    "        \n",
    "        # 将q, k, v分别通过对应W_q, W_k, W_v\n",
    "        # TODO\n",
    "        queries = self.W_q(queries)\n",
    "        keys = self.W_k(keys)\n",
    "        values = self.W_v(values)\n",
    "                \n",
    "        # 切出num_heads个头，维度变成 (batch_size, L, num_heads, num_hiddens / num_heads)\n",
    "        # TODO\n",
    "        queries = queries.reshape(queries.shape[0], queries.shape[1], self.num_heads, -1)\n",
    "        keys = keys.reshape(keys.shape[0], keys.shape[1], self.num_heads, -1)\n",
    "        values = values.reshape(values.shape[0], values.shape[1], self.num_heads, -1)\n",
    "\n",
    "        # 通过permute和reshape使维度变成 (batch_size * num_heads, L, num_hiddens / num_heads)\n",
    "        # 此时，queries[i], keys[i], values[i] 表示特定batch_id & head_id下的qkv序列\n",
    "        # TODO\n",
    "        queries = queries.permute(0, 2, 1, 3)\n",
    "        queries = queries.reshape(-1, queries.shape[2], queries.shape[3])  \n",
    "        \n",
    "        keys = keys.permute(0, 2, 1, 3)\n",
    "        keys = keys.reshape(-1, keys.shape[2], keys.shape[3])\n",
    "        \n",
    "        values = values.permute(0, 2, 1, 3)\n",
    "        values = values.reshape(-1, values.shape[2], values.shape[3])\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "        output = self.attention(queries, keys, values, valid_lens) \n",
    "        \n",
    "        # 此时output的形状是 (batch_size * num_heads, L, num_hiddens / num_heads)，把他恢复成 (batch_size，L，num_hiddens)\n",
    "        output = output.reshape(-1, self.num_heads, output.shape[1], output.shape[2])\n",
    "        output = output.permute(0, 2, 1, 3)\n",
    "        output = output.reshape(output.shape[0], output.shape[1], -1)\n",
    "\n",
    "        return self.W_o(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一下效果\n",
    "num_hiddens, num_heads = 100, 5\n",
    "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
    "                               num_hiddens, num_heads, 0.5)\n",
    "attention.eval()\n",
    "batch_size, num_queries = 2, 4\n",
    "num_kvpairs, valid_lens = 6, torch.tensor([[1, 2, 3, 4], [1, 2, 3, 4]])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
    "attention(X, Y, Y, valid_lens).shape # it should be torch.Size([2, 4, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "    \n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough `P`\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        if state[self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[self.i], X), axis=1)\n",
    "            \n",
    "        state[self.i] = key_values \n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X = self.attention(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X)\n",
    "        \n",
    "        return self.addnorm2(Y, self.ffn(Y)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderOnly(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoderOnly, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "                \n",
    "    def init_state(self, *args):\n",
    "        return [None] * self.num_layers\n",
    "    \n",
    "    def forward(self, X, state=None):\n",
    "        # 输入X形状: (batch_size, seq_length)\n",
    "        # 对每个token进行embedding并加上位置编码\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "        \n",
    "        return self.dense(X), state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 64\n",
    "num_hiddens, num_layers, dropout = sz, 2, 0.1\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = sz, sz * 2, 16\n",
    "key_size, query_size, value_size = sz, sz, sz\n",
    "norm_shape = [sz]\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerDecoderOnly(len(vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix, num_preds, net, vocab, device):\n",
    "    input_ids = [vocab[x] for x in prefix]\n",
    "    X = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "    state = net.init_state()\n",
    "    output_seq = prefix\n",
    "    output_tokens = []\n",
    "    for _ in range(num_preds):\n",
    "        Y, state = net(X, state)\n",
    "        Y = Y[:, -1, :]\n",
    "        X = Y.argmax(dim=-1)\n",
    "        pred = X.squeeze(dim=0).type(torch.int32).item()\n",
    "        output_tokens.append(pred)\n",
    "        output_seq += vocab.to_tokens(pred)\n",
    "    print(output_tokens)\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28425/221368983.py:19: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
      "  return math.exp(metric[0] / metric[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49, ppl: 11.24813676075626\n",
      "[2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Travellere the the the the the the the the the the the the \n",
      "epoch: 99, ppl: 10.111771084331037\n",
      "[2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Travellere the the the the the the the the the the the the \n",
      "epoch: 149, ppl: 8.999837280176473\n",
      "[2, 1, 3, 9, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Travellere thererererererere the the the the the the the th\n",
      "epoch: 199, ppl: 8.097530767427056\n",
      "[2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Travellere the the the the the the the the the the the the \n",
      "epoch: 249, ppl: 7.489600605522503\n",
      "[2, 6, 3, 1, 3, 9, 2, 1, 4, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerent the athe the the the the the the the the the t\n",
      "epoch: 299, ppl: 7.792213022885697\n",
      "[2, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Travellere an an an and the the the the the the the the the\n",
      "epoch: 349, ppl: 6.807894893653738\n",
      "[2, 1, 4, 12, 1, 4, 6, 11, 1, 3, 9, 2, 1, 4, 22, 2, 10, 2, 1, 4, 13, 4, 22, 2, 10, 2, 10, 2, 10, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 2, 10]\n",
      "The Time Travellere al and the avere amaverererellllllllllllllllller\n",
      "epoch: 399, ppl: 7.025268501642373\n",
      "[2, 1, 4, 10, 1, 4, 12, 7, 6, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Travellere ar alone the the the the the the the the the the\n",
      "epoch: 449, ppl: 6.705552950737188\n",
      "[2, 6, 11, 5, 15, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 19, 1, 4, 6, 11, 1, 4, 6, 7, 17, 2, 10, 2, 1, 3, 9, 2, 1, 3, 5, 10, 2, 1, 3, 5, 13, 2, 1, 3, 9]\n",
      "The Time Travellerendic and and and any and anowere the tire time th\n",
      "epoch: 499, ppl: 6.442753733283578\n",
      "[2, 6, 11, 1, 4, 1, 4, 6, 11, 1, 4, 1, 4, 1, 4, 1, 4, 6, 11, 7, 16, 7, 14, 10, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerend a and a a a andofour the the the the the the t\n",
      "epoch: 549, ppl: 6.343696109997175\n",
      "[1, 4, 12, 1, 3, 9, 5, 8, 1, 4, 12, 5, 6, 11, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 6, 7, 1, 3, 9, 4, 1, 3, 9, 4, 22, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Traveller al this alind a a a a ano tha thave the the the t\n",
      "epoch: 599, ppl: 6.0366490147409\n",
      "[13, 2, 1, 3, 10, 4, 22, 2, 12, 12, 2, 10, 1, 3, 9, 2, 10, 1, 3, 9, 2, 10, 1, 3, 9, 2, 10, 19, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerme traveller ther ther thery the the the the the t\n",
      "epoch: 649, ppl: 6.130264549255585\n",
      "[2, 6, 11, 1, 3, 9, 5, 13, 2, 1, 3, 10, 2, 1, 3, 10, 4, 22, 2, 12, 12, 2, 10, 1, 3, 9, 2, 10, 19, 1, 4, 22, 2, 10, 1, 4, 22, 2, 10, 1, 4, 22, 2, 10, 1, 4, 12, 2, 10, 1]\n",
      "The Time Travellerend thime tre traveller thery aver aver aver aler \n",
      "epoch: 699, ppl: 6.311793469712181\n",
      "[2, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6]\n",
      "The Time Travellerend and and and and and and and and and and and an\n",
      "epoch: 749, ppl: 6.033446815086433\n",
      "[2, 6, 11, 1, 4, 21, 2, 6, 11, 1, 3, 9, 2, 1, 3, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 1]\n",
      "The Time Travellerend abend the tre the the the the tis the the tis \n",
      "epoch: 799, ppl: 6.047878394399754\n",
      "[2, 6, 11, 1, 4, 21, 7, 14, 3, 1, 3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 1, 4, 22, 2, 1, 4, 6, 1, 4, 12, 12, 12, 12, 2, 10, 1, 3, 9, 5, 8, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerend about the time trave ave an allller this the t\n",
      "epoch: 849, ppl: 6.3188077025279465\n",
      "[2, 10, 1, 4, 12, 19, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 8, 4, 3, 9, 4, 3, 9, 2, 1, 8, 1, 4, 3, 9, 4, 3, 9, 2, 1, 4, 3, 9, 2, 1, 4, 3, 9, 2, 1, 4, 3]\n",
      "The Time Travellerer aly the the the sathathe s athathe athe athe at\n",
      "epoch: 899, ppl: 6.019458676800093\n",
      "[1, 4, 12, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 1, 4, 3, 1, 4, 6, 11, 1, 3, 9, 2, 10, 2, 1, 3, 9, 2, 1, 4, 22, 2, 10, 19, 7, 1, 3, 9, 2, 10, 19, 1, 3, 9, 2, 10]\n",
      "The Time Traveller al the the tis at and there the averyo thery ther\n",
      "epoch: 949, ppl: 6.050858869831527\n",
      "[3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 10, 1, 8, 1, 4, 12, 12, 12, 12, 12, 12, 2, 10, 7, 16, 1, 20, 10, 5, 6, 15, 2, 11, 1, 3, 9, 2, 1, 3, 9, 5, 13, 2, 1, 3, 9]\n",
      "The Time Travellerthe time traver s allllllerof princed the thime th\n",
      "epoch: 999, ppl: 5.930610552753173\n",
      "[1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 5, 13, 2, 1, 3, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Traveller the the tisand the the the thime tre the the the \n",
      "epoch: 1049, ppl: 5.821159822562508\n",
      "[1, 4, 12, 1, 3, 9, 4, 14, 10, 2, 1, 11, 7, 1, 3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 2, 1, 3, 10, 2, 1, 8, 4, 22, 2, 10, 19, 7, 14, 6, 18, 7, 14, 1, 13, 2, 1, 4, 6, 1]\n",
      "The Time Traveller al thaure do the time tre tre saveryoungou me an \n",
      "epoch: 1099, ppl: 5.7761786869993985\n",
      "[2, 1, 3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 10, 1, 4, 12, 12, 12, 2, 10, 1, 3, 9, 2, 10, 1, 3, 9, 2, 10, 2, 10, 1, 3, 9, 2, 10, 2, 10, 1, 3, 9, 2, 10, 2, 10]\n",
      "The Time Travellere the time traver alller ther therer therer therer\n",
      "epoch: 1149, ppl: 5.617509248604804\n",
      "[1, 4, 12, 1, 3, 9, 4, 14, 10, 2, 1, 11, 5, 13, 2, 1, 3, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 10, 2, 1]\n",
      "The Time Traveller al thaure dime tre the the the the the the there \n",
      "epoch: 1199, ppl: 5.5110000357018905\n",
      "[1, 4, 12, 1, 3, 9, 2, 10, 2, 1, 11, 5, 13, 2, 1, 3, 10, 2, 1, 3, 10, 4, 22, 2, 10, 4, 12, 12, 12, 12, 2, 10, 19, 1, 3, 9, 2, 10, 19, 1, 3, 9, 2, 8, 1, 3, 9, 2, 1, 3]\n",
      "The Time Traveller al there dime tre traverallllery thery thes the t\n",
      "epoch: 1249, ppl: 5.949405036337615\n",
      "[1, 3, 9, 2, 1, 3, 5, 8, 1, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Traveller the tis and the the the the time trave the the th\n",
      "epoch: 1299, ppl: 5.1966239846494355\n",
      "[2, 1, 3, 9, 2, 10, 2, 1, 11, 5, 13, 2, 6, 8, 5, 7, 6, 8, 1, 7, 16, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 5]\n",
      "The Time Travellere there dimensions of and and and and and and andi\n",
      "epoch: 1349, ppl: 5.639026998286851\n",
      "[1, 3, 9, 2, 1, 3, 5, 8, 1, 5, 8, 1, 5, 8, 1, 5, 8, 1, 5, 8, 1, 5, 20, 2, 7, 16, 1, 4, 6, 1, 4, 6, 11, 7, 16, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Traveller the tis is is is is ipeof an andofthe the the the\n",
      "epoch: 1399, ppl: 5.349276417830308\n",
      "[2, 1, 3, 9, 2, 1, 18, 10, 2, 1, 3, 9, 5, 13, 2, 1, 18, 10, 4, 22, 2, 12, 2, 12, 2, 10, 19, 1, 4, 6, 1, 3, 7, 16, 10, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Travellere the gre thime gravelelery an tofr the the the th\n",
      "epoch: 1449, ppl: 5.801425877544423\n",
      "[2, 10, 1, 4, 12, 12, 12, 12, 2, 24, 5, 8, 3, 2, 6, 15, 3, 2, 15, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 5, 7, 6, 3, 1, 4, 3, 1, 4, 3, 1, 4, 3, 9, 2, 10, 1, 3]\n",
      "The Time Travellerer allllexistenctectetetetetetetiont at at ather t\n",
      "epoch: 1499, ppl: 5.043125446427865\n",
      "[2, 10, 1, 4, 12, 8, 1, 4, 18, 2, 24, 20, 2, 10, 5, 13, 2, 6, 3, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 8, 3, 1, 3, 1, 3, 9, 2, 10]\n",
      "The Time Travellerer als agexperiment and and and and and ast t ther\n",
      "epoch: 1549, ppl: 5.606740078917524\n",
      "[2, 1, 3, 9, 2, 1, 18, 10, 2, 1, 3, 9, 4, 11, 1, 8, 12, 4, 3, 9, 4, 22, 2, 10, 19, 1, 8, 7, 14, 6, 18, 1, 4, 6, 18, 1, 13, 4, 6, 1, 13, 4, 6, 1, 13, 4, 6, 1, 13, 4]\n",
      "The Time Travellere the gre thad slathavery soung ang man man man ma\n",
      "epoch: 1599, ppl: 5.664309398792099\n",
      "[3, 9, 2, 1, 3, 5, 8, 1, 7, 1, 18, 10, 2, 1, 18, 10, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 1, 3, 9, 2, 1, 8, 1, 8, 7, 16, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Travellerthe tis o gre greeeeeeeeeen the s sof the the the \n",
      "epoch: 1649, ppl: 5.630524398420908\n",
      "[2, 1, 4, 10, 2, 4, 12, 12, 12, 19, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 4, 22, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 6, 7, 1, 3, 5, 8, 1, 3, 9, 2, 1]\n",
      "The Time Travellere areallly the the the thave the the tino tis the \n",
      "epoch: 1699, ppl: 5.573971519705454\n",
      "[2, 1, 3, 9, 5, 8, 1, 18, 10, 2, 1, 11, 5, 6, 1, 3, 9, 5, 8, 1, 3, 9, 4, 3, 1, 3, 1, 3, 9, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellere this gre din this that t thand the the the the t\n",
      "epoch: 1749, ppl: 5.574404105930049\n",
      "[2, 1, 3, 9, 2, 1, 18, 10, 2, 1, 11, 5, 13, 2, 6, 8, 5, 7, 6, 8, 1, 4, 6, 18, 1, 3, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 18, 2, 1, 18, 2, 1, 18]\n",
      "The Time Travellere the gre dimensions ang t the the the the ge ge g\n",
      "epoch: 1799, ppl: 5.432344950093455\n",
      "[1, 3, 9, 2, 1, 18, 10, 2, 1, 11, 5, 13, 2, 6, 8, 5, 7, 6, 8, 5, 7, 6, 8, 1, 4, 10, 1, 4, 10, 1, 4, 10, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6]\n",
      "The Time Traveller the gre dimensionsions ar ar ar an an an an an an\n",
      "epoch: 1849, ppl: 5.722313618230752\n",
      "[1, 4, 12, 1, 3, 9, 4, 3, 9, 2, 10, 2, 1, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Traveller al thathere d the the the the the the the the the\n",
      "epoch: 1899, ppl: 5.26084568773462\n",
      "[1, 3, 9, 2, 1, 11, 5, 6, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 8, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 12, 12]\n",
      "The Time Traveller the din a a a a a a a a a a s a a a a a a a a all\n",
      "epoch: 1949, ppl: 4.984951212021312\n",
      "[1, 4, 12, 2, 24, 5, 8, 3, 2, 6, 15, 2, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 19, 1, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 4, 6, 7, 1]\n",
      "The Time Traveller alexistencethe and and and any anananananananano \n",
      "epoch: 1999, ppl: 5.169648727697163\n",
      "[3, 9, 2, 1, 18, 10, 2, 1, 11, 5, 13, 2, 6, 8, 5, 7, 6, 8, 5, 7, 6, 8, 1, 7, 6, 2, 1, 7, 1, 7, 16, 1, 4, 6, 11, 1, 3, 1, 3, 9, 2, 1, 4, 6, 11, 1, 3, 1, 3, 9]\n",
      "The Time Travellerthe gre dimensionsions one o of and t the and t th\n",
      "epoch: 2049, ppl: 5.056455726948354\n",
      "[2, 1, 3, 10, 4, 22, 2, 12, 12, 12, 2, 10, 1, 3, 9, 2, 10, 1, 3, 9, 2, 1, 21, 14, 18, 9, 1, 21, 10, 2, 1, 3, 9, 5, 8, 1, 3, 9, 4, 6, 11, 1, 3, 9, 4, 6, 11, 1, 3, 9]\n",
      "The Time Travellere travelller ther the bugh bre this thand thand th\n",
      "epoch: 2099, ppl: 5.345180233154697\n",
      "[2, 1, 4, 12, 1, 3, 9, 4, 22, 2, 1, 21, 2, 1, 5, 8, 1, 4, 12, 12, 12, 1, 20, 8, 1, 21, 19, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Travellere al thave be is alll ps by the the the the the th\n",
      "epoch: 2149, ppl: 5.194717556973576\n",
      "[1, 3, 9, 2, 1, 18, 7, 20, 10, 19, 1, 4, 3, 9, 7, 14, 1, 8, 1, 4, 3, 1, 8, 2, 1, 4, 3, 1, 4, 3, 1, 4, 3, 1, 4, 3, 9, 5, 8, 1, 4, 6, 1, 4, 6, 11, 1, 3, 1, 3]\n",
      "The Time Traveller the gopry athou s at se at at at athis an and t t\n",
      "epoch: 2199, ppl: 5.283254012740994\n",
      "[1, 4, 12, 1, 3, 9, 2, 1, 22, 2, 1, 21, 2, 1, 3, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 6, 18, 2, 1, 3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 1, 3, 10, 19, 1, 3, 10, 1]\n",
      "The Time Traveller al the ve be tis the the tinge time trave try tr \n",
      "epoch: 2249, ppl: 5.223774870991561\n",
      "[2, 1, 4, 10, 2, 4, 12, 12, 12, 12, 19, 1, 3, 9, 4, 3, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 5, 6, 18, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Travellere arealllly thatthe the the the things the the the\n",
      "epoch: 2299, ppl: 5.0853179540850375\n",
      "[2, 1, 20, 12, 4, 6, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 10, 2, 1, 3, 9, 5, 8, 19, 15, 9, 5, 8, 1, 3, 1, 3, 1, 3, 9, 5, 8, 1, 3, 1, 3, 9, 5, 8, 1, 3]\n",
      "The Time Travellere plane the the the re thisychis t t this t this t\n",
      "epoch: 2349, ppl: 5.324353409831698\n",
      "[2, 1, 20, 10, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n",
      "The Time Travellere pr a a a a a a a a a a a a a a a a a a a a a a a\n",
      "epoch: 2399, ppl: 5.161252709544694\n",
      "[1, 4, 12, 1, 8, 1, 4, 18, 2, 1, 3, 2, 1, 4, 19, 1, 4, 19, 7, 16, 10, 11, 5, 11, 1, 3, 9, 4, 6, 11, 1, 3, 9, 4, 6, 7, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 4, 22, 2]\n",
      "The Time Traveller al s age te ay ayofrdid thand thano the the thave\n",
      "epoch: 2449, ppl: 5.04137389058138\n",
      "[1, 3, 9, 2, 1, 18, 7, 1, 18, 7, 10, 4, 19, 2, 10, 13, 4, 6, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 10, 13, 2, 1, 3, 10, 13, 2, 1, 3, 10, 4, 22, 2, 10, 19, 1, 3, 10, 19]\n",
      "The Time Traveller the go gorayerman the the therme trme travery try\n",
      "epoch: 2499, ppl: 5.1020953488020035\n",
      "[1, 4, 12, 1, 3, 9, 2, 10, 2, 10, 2, 10, 2, 1, 20, 8, 19, 1, 4, 15, 9, 7, 18, 5, 6, 2, 8, 8, 8, 8, 8, 8, 1, 3, 1, 3, 1, 3, 9, 7, 12, 4, 5, 11, 1, 3, 9, 2, 1, 3]\n",
      "The Time Traveller al thererere psy achoginessssss t t tholaid the t\n",
      "epoch: 2549, ppl: 5.200732799359192\n",
      "[1, 3, 9, 2, 1, 18, 10, 4, 6, 11, 1, 8, 7, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 13, 2, 1, 3, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Traveller the grand so the the the the the time tre the the\n",
      "epoch: 2599, ppl: 5.117511351683515\n",
      "[1, 3, 9, 2, 1, 18, 7, 3, 5, 6, 2, 1, 18, 2, 1, 18, 10, 13, 2, 3, 10, 5, 13, 2, 3, 10, 19, 1, 3, 10, 5, 13, 2, 1, 3, 10, 4, 6, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Traveller the gotine ge grmetrimetry trime tran the the the\n",
      "epoch: 2649, ppl: 4.939421388974407\n",
      "[1, 4, 6, 7, 3, 9, 2, 1, 22, 2, 1, 21, 14, 3, 5, 13, 2, 1, 4, 21, 14, 3, 1, 4, 21, 2, 1, 4, 21, 2, 24, 20, 2, 10, 5, 13, 2, 10, 5, 13, 2, 6, 8, 1, 3, 1, 3, 1, 3, 1]\n",
      "The Time Traveller anothe ve butime abut abe abexperimerimens t t t \n",
      "epoch: 2699, ppl: 5.247142958670689\n",
      "[21, 2, 1, 3, 9, 2, 1, 17, 4, 6, 11, 1, 4, 8, 1, 4, 12, 2, 10, 2, 1, 4, 8, 7, 1, 4, 6, 11, 1, 4, 6, 11, 1, 3, 2, 10, 2, 1, 4, 6, 7, 1, 4, 6, 7, 1, 3, 9, 5, 6]\n",
      "The Time Travellerbe the wand as alere aso and and tere ano ano thin\n",
      "epoch: 2749, ppl: 4.91927003405775\n",
      "[1, 4, 12, 1, 3, 9, 2, 1, 3, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 1, 3, 9, 2, 1, 3, 5, 8, 1, 3, 5, 8, 1, 3, 9, 2, 1, 18, 2, 1, 3, 10, 10, 10, 5, 8, 1]\n",
      "The Time Traveller al the tis the the tis the tis tis the ge trrris \n",
      "epoch: 2799, ppl: 5.250433537571597\n",
      "[5, 3, 1, 8, 1, 16, 2, 1, 3, 9, 5, 6, 11, 5, 13, 2, 11, 5, 15, 4, 12, 21, 19, 1, 4, 10, 10, 5, 8, 5, 15, 8, 5, 7, 6, 1, 19, 1, 19, 1, 17, 4, 10, 2, 6, 7, 16, 7, 6, 7]\n",
      "The Time Travellerit s fe thindimedicalby arrisicsion y y warenofono\n",
      "epoch: 2849, ppl: 4.9506542007429655\n",
      "[1, 4, 6, 11, 1, 16, 5, 13, 5, 8, 1, 3, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 11, 5, 13, 2, 1, 3, 10, 4, 6, 1, 11, 5, 13, 2, 1, 3]\n",
      "The Time Traveller and fimis te the the the the the dime tran dime t\n",
      "epoch: 2899, ppl: 5.058348799424858\n",
      "[1, 4, 10, 18, 2, 4, 10, 1, 3, 9, 1, 11, 1, 4, 6, 11, 1, 16, 3, 9, 5, 15, 4, 12, 5, 15, 2, 1, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6, 11, 1, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6]\n",
      "The Time Traveller argear th d and fthicalice the and and the and an\n",
      "epoch: 2949, ppl: 5.237497741078492\n",
      "[1, 3, 9, 2, 1, 18, 10, 4, 6, 11, 1, 3, 9, 5, 15, 4, 1, 3, 9, 2, 8, 1, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1]\n",
      "The Time Traveller the grand thica thes and the the a a a a a a a a \n",
      "epoch: 2999, ppl: 5.097352852211271\n",
      "[2, 1, 4, 10, 2, 4, 12, 12, 12, 1, 3, 9, 2, 1, 3, 9, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Travellere arealll the this the the the the the tis the the\n",
      "epoch: 3049, ppl: 5.125697508144353\n",
      "[2, 1, 4, 10, 2, 24, 5, 8, 16, 5, 8, 1, 4, 12, 21, 19, 1, 4, 12, 12, 12, 12, 12, 12, 12, 12, 1, 4, 6, 12, 2, 6, 12, 2, 6, 18, 1, 3, 1, 3, 9, 2, 1, 3, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellere arexisfis alby allllllll anlenleng t the t the t\n",
      "epoch: 3099, ppl: 5.643491662595864\n",
      "[2, 1, 4, 6, 11, 1, 16, 5, 13, 2, 6, 8, 5, 12, 21, 19, 1, 4, 21, 19, 1, 4, 21, 12, 21, 19, 1, 4, 21, 2, 15, 4, 21, 2, 15, 4, 6, 11, 1, 4, 6, 7, 16, 5, 8, 1, 17, 9, 4, 8]\n",
      "The Time Travellere and fimensilby aby ablby abecabecand anofis whas\n",
      "epoch: 3149, ppl: 5.020432534788849\n",
      "[2, 1, 4, 6, 11, 1, 16, 5, 8, 15, 2, 11, 1, 3, 9, 2, 1, 4, 12, 5, 6, 11, 1, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6, 11, 1, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11]\n",
      "The Time Travellere and fisced the alind the and and the and and and\n",
      "epoch: 3199, ppl: 4.934741860135056\n",
      "[1, 4, 12, 1, 3, 9, 2, 1, 20, 8, 19, 1, 3, 9, 4, 10, 7, 16, 7, 7, 7, 23, 5, 6, 1, 3, 1, 3, 9, 5, 8, 1, 3, 9, 5, 8, 1, 7, 6, 7, 6, 7, 6, 7, 6, 7, 6, 7, 6, 1]\n",
      "The Time Traveller al the psy tharofoookin t this this onononononon \n",
      "epoch: 3249, ppl: 5.284104328653366\n",
      "[1, 3, 9, 2, 1, 21, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 7, 21, 2, 1, 7, 20, 12, 4, 8, 19, 7, 1, 3, 9, 5, 6, 18]\n",
      "The Time Traveller the bre the the the the the the obe oplasyo thing\n",
      "epoch: 3299, ppl: 5.542948391540355\n",
      "[1, 3, 9, 2, 1, 18, 10, 4, 6, 11, 5, 10, 2, 15, 7, 6, 7, 6, 1, 3, 9, 5, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Traveller the grandireconon this the the the the the the th\n",
      "epoch: 3349, ppl: 5.208999918860896\n",
      "[1, 3, 9, 2, 1, 21, 10, 2, 1, 4, 12, 2, 24, 20, 2, 10, 5, 8, 1, 4, 6, 19, 1, 4, 15, 2, 22, 2, 18, 10, 5, 7, 6, 1, 3, 9, 7, 14, 6, 1, 3, 1, 3, 9, 4, 6, 1, 3, 5, 13]\n",
      "The Time Traveller the bre alexperis any acevegrion thoun t than tim\n",
      "epoch: 3399, ppl: 4.858602971814024\n",
      "[1, 4, 6, 11, 1, 16, 5, 13, 4, 10, 2, 11, 1, 19, 7, 14, 1, 3, 9, 4, 1, 3, 9, 2, 1, 7, 1, 7, 14, 18, 9, 4, 1, 19, 7, 14, 1, 19, 7, 14, 1, 19, 7, 14, 1, 19, 7, 14, 1, 19]\n",
      "The Time Traveller and fimared you tha the o ougha you you you you y\n",
      "epoch: 3449, ppl: 5.451935343225315\n",
      "[1, 4, 6, 11, 1, 8, 7, 1, 16, 5, 12, 21, 19, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1, 4, 6, 1]\n",
      "The Time Traveller and so filby an an an an an an an an an an an an \n",
      "epoch: 3499, ppl: 5.180696681970534\n",
      "[1, 4, 6, 11, 1, 16, 5, 8, 15, 2, 1, 3, 9, 2, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]\n",
      "The Time Traveller and fisce the a a a a a a a a a a a a a a a a a a\n",
      "epoch: 3549, ppl: 5.197873018211196\n",
      "[1, 4, 6, 11, 5, 13, 5, 8, 5, 7, 6, 8, 1, 16, 19, 2, 4, 21, 12, 21, 19, 1, 15, 7, 14, 3, 1, 3, 1, 3, 9, 4, 6, 1, 3, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9]\n",
      "The Time Traveller andimisions fyeablby cout t than t the the the th\n",
      "epoch: 3599, ppl: 4.824911238091534\n",
      "[6, 7, 17, 1, 19, 1, 4, 6, 7, 3, 9, 2, 1, 7, 3, 9, 2, 1, 3, 5, 8, 1, 13, 2, 1, 13, 2, 1, 13, 2, 1, 13, 2, 1, 13, 2, 1, 13, 2, 1, 3, 10, 2, 1, 7, 16, 10, 2, 1, 3]\n",
      "The Time Travellernow y anothe othe tis me me me me me me tre ofre t\n",
      "epoch: 3649, ppl: 4.6499580638276825\n",
      "[6, 7, 17, 1, 3, 9, 2, 10, 1, 17, 1, 17, 9, 5, 8, 1, 15, 4, 22, 2, 1, 7, 6, 1, 7, 1, 7, 1, 7, 6, 12, 19, 1, 7, 3, 9, 4, 5, 13, 7, 6, 18, 1, 7, 6, 18, 1, 7, 6, 18]\n",
      "The Time Travellernow ther w whis cave on o o only othaimong ong ong\n",
      "epoch: 3699, ppl: 5.356379183570144\n",
      "[5, 3, 1, 7, 1, 3, 9, 2, 1, 18, 10, 2, 1, 18, 10, 13, 2, 1, 7, 16, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerit o the gre grme of the the the the the the the t\n",
      "epoch: 3749, ppl: 4.891935690181875\n",
      "[1, 4, 21, 7, 14, 3, 1, 5, 6, 1, 3, 9, 2, 1, 3, 9, 2, 1, 8, 1, 8, 1, 18, 2, 1, 7, 13, 2, 24, 20, 12, 4, 15, 5, 6, 2, 15, 5, 8, 1, 13, 2, 20, 12, 4, 18, 9, 2, 15, 5]\n",
      "The Time Traveller about in the the s s ge omexplacinecis meplagheci\n",
      "epoch: 3799, ppl: 4.671792207854954\n",
      "[1, 4, 6, 11, 5, 8, 15, 3, 9, 2, 1, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11, 1, 4, 6, 11]\n",
      "The Time Traveller andiscthe and the the and and and and and and and\n",
      "epoch: 3849, ppl: 5.038058180537835\n",
      "[1, 3, 9, 2, 1, 18, 10, 4, 6, 11, 5, 15, 23, 6, 2, 8, 1, 4, 6, 11, 1, 3, 1, 4, 6, 11, 1, 3, 1, 4, 6, 11, 1, 3, 1, 3, 9, 2, 1, 4, 6, 11, 1, 3, 9, 2, 1, 4, 6, 11]\n",
      "The Time Traveller the grandicknes and t and t and t the and the and\n",
      "epoch: 3899, ppl: 5.085588334117307\n",
      "[1, 4, 21, 7, 14, 3, 1, 5, 6, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 18, 9, 2, 1, 18, 2, 1, 18, 2, 1, 18, 10, 7, 4, 10, 7, 4, 22, 2, 1, 3, 9, 3, 9, 1, 3, 9, 1]\n",
      "The Time Traveller about in the the the ghe ge ge groaroave thth th \n",
      "epoch: 3949, ppl: 4.900000493280829\n",
      "[1, 4, 6, 11, 1, 16, 5, 12, 21, 19, 1, 17, 9, 5, 3, 1, 9, 4, 8, 1, 9, 4, 6, 11, 1, 9, 4, 6, 11, 1, 9, 4, 6, 11, 1, 9, 4, 6, 11, 1, 9, 4, 6, 11, 1, 9, 4, 6, 11, 1]\n",
      "The Time Traveller and filby whit has hand hand hand hand hand hand \n",
      "epoch: 3999, ppl: 5.144859109191919\n",
      "[1, 4, 18, 2, 24, 20, 2, 6, 19, 5, 10, 5, 10, 5, 13, 2, 6, 3, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 3, 9, 5, 8, 1, 8, 1]\n",
      "The Time Traveller agexpenyiririment a a a a a a a a a a a a this s \n",
      "epoch: 4049, ppl: 4.98709395264439\n",
      "[1, 4, 6, 11, 1, 8, 7, 17, 6, 1, 3, 9, 2, 1, 4, 5, 16, 1, 21, 19, 2, 18, 8, 1, 3, 9, 2, 10, 2, 2, 6, 1, 3, 9, 2, 10, 2, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2]\n",
      "The Time Traveller and sown the aif byegs thereen theree the the the\n",
      "epoch: 4099, ppl: 5.054559747644621\n",
      "[1, 4, 1, 4, 6, 7, 3, 9, 2, 1, 18, 2, 1, 18, 2, 1, 18, 10, 1, 18, 12, 4, 11, 1, 3, 9, 5, 15, 23, 6, 18, 9, 3, 9, 2, 8, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Traveller a anothe ge ge gr glad thicknghthes the the the t\n",
      "epoch: 4149, ppl: 4.870522252093051\n",
      "[1, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 21, 10, 2, 1, 21, 10, 2, 1, 17]\n",
      "The Time Traveller and the the the the the the the the the bre bre w\n",
      "epoch: 4199, ppl: 5.007533887239582\n",
      "[2, 1, 17, 7, 10, 1, 9, 7, 6, 18, 2, 1, 17, 9, 7, 6, 18, 2, 1, 3, 9, 2, 1, 17, 9, 2, 1, 10, 2, 1, 17, 9, 7, 6, 1, 17, 9, 2, 1, 10, 2, 1, 17, 9, 7, 6, 1, 17, 9, 7]\n",
      "The Time Travellere wor honge whonge the whe re whon whe re whon who\n",
      "epoch: 4249, ppl: 4.687130991165808\n",
      "[5, 3, 2, 1, 16, 7, 14, 10, 1, 11, 5, 13, 2, 6, 8, 5, 7, 6, 8, 5, 7, 6, 8, 1, 3, 9, 2, 11, 21, 2, 1, 3, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellerite four dimensionsions thedbe t the the the the t\n",
      "epoch: 4299, ppl: 4.797098061973276\n",
      "[1, 4, 12, 1, 3, 9, 2, 1, 21, 2, 1, 17, 4, 10, 2, 1, 4, 12, 2, 1, 3, 9, 5, 8, 1, 3, 9, 5, 8, 1, 3, 9, 4, 22, 2, 1, 4, 3, 9, 5, 8, 1, 4, 3, 1, 4, 3, 9, 2, 1]\n",
      "The Time Traveller al the be ware ale this this thave athis at athe \n",
      "epoch: 4349, ppl: 4.984473455912856\n",
      "[1, 4, 6, 11, 5, 13, 5, 10, 2, 11, 1, 3, 12, 19, 1, 3, 1, 3, 9, 2, 6, 8, 5, 13, 2, 6, 1, 3, 1, 3, 1, 3, 9, 5, 13, 2, 1, 3, 10, 2, 1, 3, 10, 2, 1, 7, 16, 5, 13, 2]\n",
      "The Time Traveller andimired tly t thensimen t t thime tre tre ofime\n",
      "epoch: 4399, ppl: 4.8018227959245445\n",
      "[1, 4, 6, 11, 1, 4, 6, 7, 17, 9, 19, 1, 8, 1, 3, 9, 10, 2, 1, 3, 9, 10, 2, 1, 3, 9, 5, 13, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Traveller and anowhy s thre thre thime the the the the the \n",
      "epoch: 4449, ppl: 4.791930101790728\n",
      "[6, 1, 4, 1, 4, 1, 13, 4, 6, 1, 4, 6, 11, 1, 6, 7, 1, 3, 9, 2, 1, 22, 2, 1, 5, 13, 2, 1, 3, 10, 2, 1, 3, 10, 2, 1, 3, 10, 1, 3, 10, 5, 16, 10, 2, 1, 3, 9, 2, 1]\n",
      "The Time Travellern a a man and no the ve ime tre tre tr trifre the \n",
      "epoch: 4499, ppl: 4.763908361285932\n",
      "[6, 1, 4, 1, 4, 12, 1, 3, 9, 2, 1, 21, 2, 1, 3, 7, 1, 3, 9, 2, 1, 3, 9, 2, 1, 18, 5, 13, 2, 1, 3, 10, 5, 15, 5, 8, 1, 7, 14, 20, 12, 4, 6, 11, 1, 3, 9, 2, 1, 3]\n",
      "The Time Travellern a al the be to the the gime tricis oupland the t\n",
      "epoch: 4549, ppl: 5.2226447519335695\n",
      "[6, 18, 1, 4, 1, 4, 6, 11, 1, 16, 5, 12, 21, 19, 1, 9, 4, 6, 11, 1, 17, 9, 2, 6, 11, 1, 9, 2, 6, 11, 1, 9, 2, 6, 11, 1, 9, 2, 4, 6, 11, 1, 9, 2, 4, 6, 11, 1, 4, 6]\n",
      "The Time Travellerng a and filby hand whend hend hend heand heand an\n",
      "epoch: 4599, ppl: 5.013345527607977\n",
      "[1, 4, 6, 11, 1, 4, 6, 7, 17, 2, 1, 8, 7, 1, 4, 5, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 5, 16, 3, 9, 2, 1, 14, 10, 2, 1, 3, 9, 4, 22, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "The Time Traveller and anowe so aid the the ifthe ure thave the the \n",
      "epoch: 4649, ppl: 4.634669657598136\n",
      "[6, 2, 8, 1, 4, 12, 1, 3, 9, 2, 10, 2, 1, 11, 1, 17, 4, 22, 7, 1, 3, 9, 4, 19, 1, 3, 9, 4, 3, 9, 4, 3, 9, 4, 3, 9, 2, 1, 3, 9, 4, 3, 9, 2, 1, 3, 9, 4, 3, 9]\n",
      "The Time Travellernes al there d wavo thay thathathathe thathe thath\n",
      "epoch: 4699, ppl: 4.706945225070321\n",
      "[6, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 3, 9, 5, 6, 11, 1, 8, 2, 1, 4, 1, 4, 1, 4, 1, 4, 6, 11, 1, 6, 11, 1, 6, 11, 1, 6, 11, 1, 6, 11, 1, 6]\n",
      "The Time Travellern a a a a a a a a thind se a a a and nd nd nd nd n\n",
      "epoch: 4749, ppl: 5.037319517189518\n",
      "[1, 4, 6, 11, 1, 17, 9, 19, 8, 7, 3, 9, 4, 8, 1, 9, 4, 3, 1, 9, 4, 3, 1, 9, 4, 3, 1, 9, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 9, 4, 3, 1, 3, 1, 3, 9, 5, 8, 1]\n",
      "The Time Traveller and whysothas hat hat hat he t t t t that t this \n",
      "epoch: 4799, ppl: 4.798580548624267\n",
      "[6, 7, 3, 1, 4, 21, 12, 2, 18, 10, 4, 15, 23, 1, 3, 9, 1, 3, 9, 4, 6, 11, 1, 3, 9, 5, 15, 23, 6, 2, 8, 8, 8, 8, 8, 1, 4, 6, 2, 1, 4, 6, 11, 1, 4, 6, 2, 1, 4, 6]\n",
      "The Time Travellernot ablegrack th thand thicknesssss ane and ane an\n",
      "epoch: 4849, ppl: 5.24968876886124\n",
      "[1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 6, 7, 3, 9, 5, 8, 1, 5, 8, 1, 5, 8, 1, 5, 11, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 20, 8, 1, 3, 9, 2]\n",
      "The Time Traveller a a a a a a a anothis is is id the the the ps the\n",
      "epoch: 4899, ppl: 4.590971242546654\n",
      "[19, 1, 19, 7, 14, 1, 15, 4, 6, 7, 3, 1, 18, 1, 3, 9, 4, 3, 1, 18, 9, 2, 1, 3, 9, 2, 1, 8, 1, 8, 15, 9, 5, 6, 2, 1, 13, 4, 6, 11, 1, 3, 9, 2, 1, 3, 9, 2, 10, 2]\n",
      "The Time Travellery you canot g that ghe the s schine mand the there\n",
      "epoch: 4949, ppl: 4.629547540199737\n",
      "[6, 7, 3, 1, 22, 2, 10, 1, 3, 9, 2, 10, 19, 1, 19, 1, 19, 1, 19, 7, 14, 6, 18, 4, 3, 5, 6, 11, 5, 6, 1, 13, 4, 3, 1, 13, 4, 3, 1, 13, 4, 3, 9, 2, 6, 11, 2, 6, 11, 2]\n",
      "The Time Travellernot ver thery y y youngatindin mat mat mathendende\n",
      "epoch: 4999, ppl: 4.786322070021185\n",
      "[6, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 3, 9, 4, 1, 18, 2, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3]\n",
      "The Time Travellern a a a a a a a a a tha ge a a a a a a a t t t t t\n",
      "[1, 4, 21, 4, 18, 7, 5, 20, 10, 4, 2, 24, 4, 21, 4, 18, 5, 3, 9, 5, 6, 7, 4, 6, 7, 15, 4, 6, 7, 16, 7, 16, 5, 20, 10, 4, 18, 4, 21, 4, 6, 7, 16, 5, 6, 7, 16, 2, 4, 18]\n",
      "The Time Traveller abagoipraexabagithinoanocanofofipragabanofinofeag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x74f21bc15450>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_epoch(net, train_iter, loss, optimizer, device):\n",
    "    metric = [0, 0]\n",
    "    state = None\n",
    "    for X, Y in train_iter:\n",
    "        state = net.init_state()\n",
    "        y = Y.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        y_hat = y_hat.view(-1, y_hat.shape[-1])\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metric[0] += l * y.numel()\n",
    "        metric[1] += y.numel()\n",
    "        \n",
    "    return math.exp(metric[0] / metric[1])\n",
    "\n",
    "def train(net, train_iter, vocab, lr, num_epochs, device):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr)\n",
    "    cur_predict = lambda prefix: predict(prefix, 50, net, vocab, device)\n",
    "    ppl_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl = train_epoch(\n",
    "            net, train_iter, loss, optimizer, device)\n",
    "        ppl_list.append(ppl)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'epoch: {epoch}, ppl: {ppl}')\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                print(cur_predict('The Time Traveller'))\n",
    "            net.train()\n",
    "            \n",
    "    print(cur_predict('The Time Traveller'))\n",
    "    return ppl_list\n",
    "lr, num_epochs = 0.01, 5000\n",
    "ppl_list = train(model, train_iter, vocab, lr, num_epochs, device)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(ppl_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
